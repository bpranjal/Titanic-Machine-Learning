# -*- coding: utf-8 -*-
"""PROJECT LOGISTIC REGRESSION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q2U9QA9s4WxYVo1VE5w7bfL8pPfHVe4e
"""

y!git clone https://github.com/bpranjal/firstProjectECC.git     #clones the github repsitory

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/firstProjectECC/titanic_train.csv')

dataset.head()

sns.countplot('Sex',data = dataset)    #we get the rough estimate of number of males and females

sns.countplot('Pclass',data = dataset)    #number of people travelling in the classes

sns.countplot('Survived',data = dataset)   #0 represents dead and 1 represents alive

#countplot used when we have categiorical data(data having types)

sns.countplot('Embarked',data = dataset)   # s stands for southampton , Q for queenstown , C for cherbourg

sns.catplot('Pclass' , data=dataset ,hue='Survived',kind='count')    # no of people dead and alive in a partiular class

sns.boxplot(dataset.Age)    #it shows the density....the shaded part are called the outlier
plt.show

sns.boxplot(y=dataset.Fare)    #outliers need to be handled
plt.show

sns.distplot(dataset.Age)    #this data is quite normalized

sns.distplot(dataset.Fare)

sns.scatterplot(x=dataset.Age, y= dataset.Fare)

sns.heatmap(dataset.corr())

sns.pairplot(dataset)

train=dataset

train.groupby('Pclass').mean()['Age'].round()   #data cleanig to remove the na values hence to replace the na values we calculate the means

mean_class1=train.groupby('Pclass').mean()['Age'].round() .loc[1]
mean_class2=train.groupby('Pclass').mean()['Age'].round() .loc[2]
mean_class3=train.groupby('Pclass').mean()['Age'].round() .loc[3]

print(mean_class1,mean_class2,mean_class3)

train.isna().sum()    #to calculate the total numbers of na values..if wedo not write sum then you will get the complete analysis....also if the person has survived or nhot does not depend upon the cabin ....hence,we are deleting the cabin row

train.drop('Cabin',axis=1,inplace=True)

sex=pd.get_dummies(train['Sex'])
sex

embarked=pd.get_dummies(train['Embarked'],drop_first=True)
embarked

train=pd.concat([train,sex,embarked],axis=1)

train.drop(['Sex',"Name",'Ticket'],axis=1,inplace=True)

train.head()      #now we only have the columns we are concerned with

#do the same steps for the test dataset

x=train.drop('Survived',axis=1)
y=train['Survived']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test=train_test_split(x,y, test_size=0.3,random_state=101)

from sklearn.linear_model import logisticRegression

X_train.drop('Age',axis=1)







